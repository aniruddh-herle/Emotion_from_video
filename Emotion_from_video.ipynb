{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Emotion_from_video.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUHbCB-XPutt"
      },
      "source": [
        "from PIL import Image\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.models import load_model"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Bt6Zw2ZQRyx"
      },
      "source": [
        "emotion_dict= {'Angry': 0, 'Sad': 5, 'Neutral': 4, 'Disgust': 1, 'Surprise': 6, 'Fear': 2, 'Happy': 3}\n",
        "\n",
        "model = load_model(r'/content/model_v6_23.hdf5')"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tnB9WNZ9P-tp",
        "outputId": "e332f2b9-8ac9-45e5-dd2a-ae725f63b48d"
      },
      "source": [
        "cap = cv2.VideoCapture(r'/content/musics.mp4')\n",
        "\n",
        "if (cap.isOpened()== False):\n",
        "\n",
        "  print(\"Error opening video stream or file\")\n",
        "\n",
        "\n",
        "while(cap.isOpened()):\n",
        "  # Capture frame-by-frame\n",
        "\n",
        "  ret, frame = cap.read()\n",
        "  if ret == True:\n",
        "    face_image = cv2.resize(frame, (48,48))\n",
        "    face_image = cv2.cvtColor(face_image, cv2.COLOR_BGR2GRAY)\n",
        "    face_image = np.reshape(face_image, [1, face_image.shape[0], face_image.shape[1], 1])\n",
        "    #cv2_imshow(face_image)\n",
        "    predicted_class = np.argmax(model.predict(face_image))\n",
        "    label_map = dict((v,k) for k,v in emotion_dict.items())\n",
        "    predicted_label = label_map[predicted_class]\n",
        "    print(predicted_label)\n",
        "    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
        "      break\n",
        "  else:\n",
        "  \tbreak\n",
        "  \t\n",
        "\n",
        "\n",
        "\n",
        "# When everything done, release the video capture object\n",
        "cap.release()\n",
        "# Closes all the frames\n",
        "cv2.destroyAllWindows()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Surprise\n",
            "Surprise\n",
            "Surprise\n",
            "Surprise\n",
            "Surprise\n",
            "Surprise\n",
            "Surprise\n",
            "Surprise\n",
            "Surprise\n",
            "Surprise\n",
            "Surprise\n",
            "Surprise\n",
            "Surprise\n",
            "Surprise\n",
            "Surprise\n",
            "Surprise\n",
            "Surprise\n",
            "Surprise\n",
            "Surprise\n",
            "Surprise\n",
            "Surprise\n",
            "Surprise\n",
            "Surprise\n",
            "Surprise\n",
            "Surprise\n",
            "Surprise\n",
            "Surprise\n",
            "Surprise\n",
            "Surprise\n",
            "Surprise\n",
            "Surprise\n",
            "Surprise\n",
            "Surprise\n",
            "Surprise\n",
            "Surprise\n",
            "Surprise\n",
            "Surprise\n",
            "Surprise\n",
            "Surprise\n",
            "Surprise\n",
            "Surprise\n",
            "Surprise\n",
            "Surprise\n",
            "Surprise\n",
            "Surprise\n",
            "Surprise\n",
            "Surprise\n",
            "Surprise\n",
            "Surprise\n",
            "Surprise\n",
            "Surprise\n",
            "Surprise\n",
            "Surprise\n",
            "Surprise\n",
            "Surprise\n",
            "Surprise\n",
            "Surprise\n",
            "Surprise\n",
            "Surprise\n",
            "Surprise\n",
            "Surprise\n",
            "Surprise\n",
            "Surprise\n",
            "Surprise\n",
            "Surprise\n",
            "Surprise\n",
            "Surprise\n",
            "Surprise\n",
            "Surprise\n",
            "Surprise\n",
            "Surprise\n",
            "Fear\n",
            "Fear\n",
            "Fear\n",
            "Fear\n",
            "Fear\n",
            "Surprise\n",
            "Surprise\n",
            "Surprise\n",
            "Surprise\n",
            "Surprise\n",
            "Surprise\n",
            "Surprise\n",
            "Surprise\n",
            "Surprise\n",
            "Surprise\n",
            "Surprise\n",
            "Surprise\n",
            "Fear\n",
            "Fear\n",
            "Fear\n",
            "Fear\n",
            "Surprise\n",
            "Surprise\n",
            "Fear\n",
            "Fear\n",
            "Fear\n",
            "Surprise\n",
            "Surprise\n",
            "Surprise\n",
            "Surprise\n",
            "Surprise\n",
            "Surprise\n",
            "Surprise\n",
            "Surprise\n",
            "Surprise\n",
            "Surprise\n",
            "Surprise\n",
            "Surprise\n",
            "Surprise\n",
            "Surprise\n",
            "Surprise\n",
            "Surprise\n",
            "Surprise\n",
            "Surprise\n",
            "Surprise\n",
            "Surprise\n",
            "Surprise\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}